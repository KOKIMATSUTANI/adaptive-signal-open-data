# docker/Dockerfile.train
# RL/MIP training only
# Future GPU support (CUDA-based replacement) can be completed in this layer only. Separate training libraries (torch, etc.) from others
ARG BASE_IMAGE=tram-base:latest
FROM ${BASE_IMAGE}

# Python dependencies for training only (heavy and GPU-capable)
COPY requirements/train.txt /tmp/requirements-train.txt
RUN pip install -r /tmp/requirements-train.txt \
    && rm /tmp/requirements-train.txt

# Copy training code
COPY src/training/ ./src/training/
COPY configs/train/ ./configs/train/

# Volume for training results and models
VOLUME ["/app/models", "/app/results"]

# Run training
ENTRYPOINT ["python", "-m", "src.training.trainer"]
CMD ["--config", "configs/train/default.yaml"]

# Usage examples:
# docker run --rm -v /host/models:/app/models -v /host/results:/app/results tram-train:latest
# docker run --rm -v /host/models:/app/models tram-train:latest --algorithm qddqn --episodes 1000

# GPU support version (future expansion):
# FROM nvidia/cuda:11.8-devel-ubuntu20.04 as cuda-base
# ARG BASE_IMAGE=tram-base:latest
# FROM ${BASE_IMAGE}
# # Install CUDA-compatible PyTorch, etc.
